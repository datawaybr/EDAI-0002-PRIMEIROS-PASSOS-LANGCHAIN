{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_38488/2026056485.py:9: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  multiplicar.args_schema.schema()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'description': 'Multiplica dois números',\n",
       " 'properties': {'a': {'title': 'A', 'type': 'integer'},\n",
       "  'b': {'title': 'B', 'type': 'integer'}},\n",
       " 'required': ['a', 'b'],\n",
       " 'title': 'multiplicar',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiplicar(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplica dois números\"\"\"\n",
    "    return a * b\n",
    " \n",
    "multiplicar.args_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_38488/20763493.py:16: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  multiplicar_lista.args_schema.schema()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'properties': {'numeros': {'description': 'Lista de números',\n",
       "   'items': {'type': 'integer'},\n",
       "   'title': 'Numeros',\n",
       "   'type': 'array'}},\n",
       " 'required': ['numeros'],\n",
       " 'title': 'CalculadoraLista',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class CalculadoraLista(BaseModel):\n",
    "    numeros: List[int] = Field(description=\"Lista de números\")\n",
    "\n",
    "@tool(\"multiplicar_lista\", args_schema=CalculadoraLista, return_direct=True)\n",
    "def multiplicar_lista(numeros: list) -> int:\n",
    "    \"\"\"Multiplica uma lista de números\"\"\"\n",
    "    produto = 1\n",
    "    for numero in numeros:\n",
    "        produto = produto * numero\n",
    "    return produto\n",
    "\n",
    "multiplicar_lista.args_schema.schema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_38488/3242570649.py:12: LangChainBetaWarning: This API is in beta and may change in the future.\n",
      "  chain_tool = chain.as_tool(name=\"Piadas\", description=\"Conta uma piada sobre um determinado tópico\")\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv() \n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "prompt = ChatPromptTemplate.from_template(\"Me conte uma piada sobre {topico}\")\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "chain_tool = chain.as_tool(name=\"Piadas\", description=\"Conta uma piada sobre um determinado tópico\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'properties': {'topico': {'title': 'Topico', 'type': 'string'}},\n",
       " 'required': ['topico'],\n",
       " 'title': 'PromptInput',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_tool.args_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: LangChain\n",
      "Summary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=500)\n",
    "tool = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "\n",
    "print(tool.invoke({\"query\": \"langchain\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_wikipedia = llm.bind_tools([tool])\n",
    "response = llm_wikipedia.invoke(\"o que é o langchain?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_xwzXpPkqfOwyu3fpB0lnthZ0', 'function': {'arguments': '{\"query\":\"LangChain\"}', 'name': 'wikipedia'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 88, 'total_tokens': 102, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_6fc10e10eb', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-4ff9a4a1-d04b-42c9-873b-024fb70ae3c9-0', tool_calls=[{'name': 'wikipedia', 'args': {'query': 'LangChain'}, 'id': 'call_xwzXpPkqfOwyu3fpB0lnthZ0', 'type': 'tool_call'}], usage_metadata={'input_tokens': 88, 'output_tokens': 14, 'total_tokens': 102, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wikipedia_chain = llm.bind_tools([tool]) | (lambda x: x.tool_calls[0][\"args\"]) | tool | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Page: LangChain\\nSummary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\\n\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wikipedia_chain.invoke(\"O que é o langchain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_pos_tool = \"\"\"\n",
    "O usuário fez uma busca na Wikipedia que retornou o seguinte conteúdo:\n",
    "{query}\n",
    "\n",
    "Resuma para ele de um modo intuitivo\n",
    "\"\"\"\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "prompt_pos_tool = PromptTemplate.from_template(prompt_pos_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wikipedia_chain = llm.bind_tools([tool]) | (lambda x: x.tool_calls[0][\"args\"]) | tool | prompt_pos_tool | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Um banco de dados vetorial é um tipo de banco de dados que armazena vetores, que são listas de números que representam dados em um espaço de muitas dimensões. Ele permite que você busque informações de forma eficiente, usando algoritmos que ajudam a encontrar rapidamente os dados mais próximos de um vetor de consulta. Em resumo, é uma ferramenta que facilita a busca e a organização de dados complexos de maneira rápida e eficaz.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wikipedia_chain.invoke(\"llamaindex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'adicao',\n",
       " 'args': {'a': 12, 'b': 7},\n",
       " 'id': 'call_khFKz99uZgM8WmnbAIIIHLoT',\n",
       " 'type': 'tool_call'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def adicao(a: int, b: int) -> int:\n",
    "    \"\"\"Adiciona dois números\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiplicacao(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplica dois numeros\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "tools = [adicao, multiplicacao]\n",
    "\n",
    "llm_tools= llm.bind_tools(tools)\n",
    "llm_tools.invoke(\"Quanto é 12 + 7?\").tool_calls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'multiplicacao',\n",
       " 'args': {'a': 12, 'b': 7},\n",
       " 'id': 'call_nfgKjlyaObKqGzH8m9b6qZJC',\n",
       " 'type': 'tool_call'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_sempre_multiplicacao = llm.bind_tools(tools,tool_choice=\"multiplicacao\")\n",
    "llm_sempre_multiplicacao.invoke(\"Quanto é 12 + 7?\").tool_calls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'adicao',\n",
       " 'args': {'a': 5, 'b': 10},\n",
       " 'id': 'call_U1XE8yeTMkeQxa3fLcrs5KcP',\n",
       " 'type': 'tool_call'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_sempre_tool = llm.bind_tools(tools,tool_choice=\"any\")\n",
    "llm_sempre_tool.invoke(\"Olá, como você está hoje?\").tool_calls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Olá! Estou aqui e pronto para ajudar. Como posso assisti-lo hoje?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 77, 'total_tokens': 94, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_6fc10e10eb', 'finish_reason': 'stop', 'logprobs': None}, id='run-33e6ba8c-6d12-41a1-83cb-d4cad1736d62-0', usage_metadata={'input_tokens': 77, 'output_tokens': 17, 'total_tokens': 94, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_sempre_tool = llm.bind_tools(tools)\n",
    "llm_sempre_tool.invoke(\"Olá, como você está hoje?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cursolangchain-2sMNaNbo-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
